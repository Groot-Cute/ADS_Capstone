{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# <center>Malaria Detection Model</center>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "The data source for the same is obtained from Kaggel.com and the link to the data source is - https://www.kaggle.com/iarunava/cell-images-for-detecting-malaria. The original data source is from the NIH Website: https://ceb.nlm.nih.gov/repositories/malaria-datasets/.\n\nThe data is provided in a single cell image folder, which in turn contains two folders - Parasitized (containing images of cells that are infected and Uninfected (containing images of cells that are not infected). Both folders contain 13779 images each. For the purpose of this model creation I am only using 500 images from each set making a data set of 1000 images. The reason for the same is resources constraints while loading the files into Watson studio and also a slow internet connection at my end.\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "The first step of the process is to import all the necessary libraries. There are few more which are imported later on as and when the need arises", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "Using TensorFlow backend.\n"
                }
            ], 
            "source": "import numpy as np # linear algebra\nimport pandas as pd \nimport os, sys\nfrom IPython.display import display\nfrom IPython.display import Image as _Imgdis\nfrom PIL import Image\nfrom sklearn.model_selection  import train_test_split\nfrom scipy import ndimage\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.utils import to_categorical\nfrom keras.optimizers import Adadelta\nfrom keras import backend as K"
        }, 
        {
            "source": "The files were loaded as two streaming body object each containing a zip folder of 500 images of uninfected & parasitized cells.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Below is the streaming body object creation code for the zip folder containing the parasitized images.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by Watson Studio for sharing."
        }, 
        {
            "source": "Below is the streaming body object creation code for the zip folder containing the uninfected images.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about your possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/\nstreaming_body_6 = client_acbfbc181f5a4f93b6155e38c3fdbb33.get_object(Bucket='adsfinalproject-donotdelete-pr-tzflpkevbjjbwo', Key='Uninfected_500.zip')['Body']\n# add missing __iter__ method so pandas accepts body as file-like object\nif not hasattr(streaming_body_6, \"__iter__\"): streaming_body_6.__iter__ = types.MethodType( __iter__, streaming_body_6 )\n"
        }, 
        {
            "source": "Reading the streaming body object as a zip file and initializing the same to a variable.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from io import BytesIO\nimport zipfile\n\nzip_parasitized = zipfile.ZipFile(BytesIO(streaming_body_5.read()), 'r')"
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "zip_uninfected = zipfile.ZipFile(BytesIO(streaming_body_6.read()), 'r')"
        }, 
        {
            "source": "The images are all color images hence setting the channel value to 3, after looking at several images setting the base width and base height at 140 and 120. The exercise can be done by reducing the dimensions or converting the images to a greyscale.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "channels = 3\nbasewidth= 140\nbaseheight = 120\ninput_shape = (channels,baseheight,basewidth)"
        }, 
        {
            "source": "### Converting the images into Numeric Data.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Initializing empty data sets to load the numeric data. Creating for loop to loop through the zip folder which has the 500 images of uninfected cells. Resizing using the base width and base height values. Also using the channel first data format while converting the image to arrays. Also creating the label data set, with a value of zero.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "x_unin_data = []\ny_unin_label = []\nfor i in range(0,len(zip_uninfected.namelist())):\n    y_unin_label.append(0)\n    img = Image.open((zip_uninfected.open(zipfile.ZipFile.namelist(zip_uninfected)[i])))\n    img = img.resize((basewidth, baseheight), Image.ANTIALIAS)\n    image_dt = img_to_array(img,data_format='channels_first')\n    image_dt = image_dt/255\n    x_unin_data.append(image_dt)"
        }, 
        {
            "source": "Ensuring that 500 sets of data is present in the image array and the label data sets.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "500\n500\n"
                }
            ], 
            "source": "print(len(x_unin_data))\nprint(len(y_unin_label))"
        }, 
        {
            "source": "Repeating the exercise for the parasitized images zip folder. This time the label is assigned to 1.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 9, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "x_para_data = []\ny_para_label = []\nfor i in range(0,len(zip_parasitized.namelist())):\n    y_para_label.append(1)\n    img = Image.open((zip_parasitized.open(zipfile.ZipFile.namelist(zip_parasitized)[i])))\n    img = img.resize((basewidth, baseheight), Image.ANTIALIAS)\n    image_dt = img_to_array(img,data_format='channels_first')\n    image_dt = image_dt/255\n    x_para_data.append(image_dt)"
        }, 
        {
            "execution_count": 10, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "500\n500\n"
                }
            ], 
            "source": "print(len(x_para_data))\nprint(len(y_para_label))"
        }, 
        {
            "source": "Combining the two individual data sets to form the combined data set.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "X = x_unin_data + x_para_data\nY = y_unin_label + y_para_label"
        }, 
        {
            "source": "Ensuring that the data count is correct.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "1000\n1000\n"
                }
            ], 
            "source": "print(len(X))\nprint(len(Y))"
        }, 
        {
            "source": "Converting the data into numpy arrays and ensuring the data count is correct again.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 13, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "1000\n1000\n"
                }
            ], 
            "source": "X = np.array(X)\nY = np.array(Y)\nprint(X.shape[0])\nprint(Y.shape[0])"
        }, 
        {
            "source": "Splitting the data set into train and test data with a ratio of 70 to 30.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 14, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=42, test_size=0.3)"
        }, 
        {
            "source": "Converting the label datasets into categorical values.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 15, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "y_train = to_categorical(y_train,2)\ny_test = to_categorical(y_test,2)"
        }, 
        {
            "source": "The approach I have adopted here is to create a convolutional neural network using keras. By keeping all other parameters as constants, I have studies the effect of applying various optimizers on the training data set and evaluating the same using the test data set. Accuracy and Loss are used as the measures to determine the fit of the models.\n\nThe names of optimizers being used for the analysis are stored in a list. A list to store the accuracy and loss value is also created. A for loop is constructed to loop over the optimizer names and define the model, train it and test it. The model definition has been included in the for loop to ensure that layers don\u2019t keep increasing with each iteration.\nThe first layer is a Convolution 2d layer with 16 neurons and activation value of relu. The second layer has 32 neurons with the same activation value. Max pooling is set to a pool size (2,2). We have added a drop out layer which drops off 25 percent of the neurons to prevent overfitting. The third layer is a dense layer with 64 neurons and activation value of relu again. Next one more drop out layer is added to drop 50 percent of the neurons. Final layer is a dense layer with two neuron for the two classifiers and a softmax activation.\n\nThe epoch is set to a value of 10 and batch size to 25 for all the iterations.\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 16, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Train on 700 samples, validate on 300 samples\nEpoch 1/10\n700/700 [==============================] - 79s 112ms/step - loss: 0.9702 - acc: 0.5329 - val_loss: 0.6871 - val_acc: 0.5200\nEpoch 2/10\n700/700 [==============================] - 79s 112ms/step - loss: 0.6860 - acc: 0.5386 - val_loss: 0.6822 - val_acc: 0.5933\nEpoch 3/10\n700/700 [==============================] - 80s 114ms/step - loss: 0.6769 - acc: 0.5814 - val_loss: 0.6733 - val_acc: 0.6500\nEpoch 4/10\n700/700 [==============================] - 81s 115ms/step - loss: 0.6501 - acc: 0.6186 - val_loss: 0.6511 - val_acc: 0.6600\nEpoch 5/10\n700/700 [==============================] - 78s 111ms/step - loss: 0.6403 - acc: 0.6214 - val_loss: 0.6304 - val_acc: 0.6867\nEpoch 6/10\n700/700 [==============================] - 79s 112ms/step - loss: 0.6135 - acc: 0.6671 - val_loss: 0.6147 - val_acc: 0.6900\nEpoch 7/10\n700/700 [==============================] - 82s 117ms/step - loss: 0.5886 - acc: 0.6814 - val_loss: 0.5953 - val_acc: 0.7267\nEpoch 8/10\n700/700 [==============================] - 79s 112ms/step - loss: 0.5645 - acc: 0.7186 - val_loss: 0.6064 - val_acc: 0.6733\nEpoch 9/10\n700/700 [==============================] - 77s 111ms/step - loss: 0.5495 - acc: 0.7114 - val_loss: 0.5673 - val_acc: 0.7467\nEpoch 10/10\n700/700 [==============================] - 78s 112ms/step - loss: 0.5069 - acc: 0.7414 - val_loss: 0.5362 - val_acc: 0.7833\n300/300 [==============================] - 18s 59ms/step\nTrain on 700 samples, validate on 300 samples\nEpoch 1/10\n700/700 [==============================] - 77s 110ms/step - loss: 0.7899 - acc: 0.5143 - val_loss: 0.6808 - val_acc: 0.5833\nEpoch 2/10\n700/700 [==============================] - 78s 111ms/step - loss: 0.6754 - acc: 0.5943 - val_loss: 0.6721 - val_acc: 0.5833\nEpoch 3/10\n700/700 [==============================] - 77s 110ms/step - loss: 0.6570 - acc: 0.6014 - val_loss: 0.6561 - val_acc: 0.6433\nEpoch 4/10\n700/700 [==============================] - 77s 111ms/step - loss: 0.6493 - acc: 0.6271 - val_loss: 0.6547 - val_acc: 0.6333\nEpoch 5/10\n700/700 [==============================] - 76s 109ms/step - loss: 0.6293 - acc: 0.6357 - val_loss: 0.6531 - val_acc: 0.6067\nEpoch 6/10\n700/700 [==============================] - 76s 109ms/step - loss: 0.6280 - acc: 0.6414 - val_loss: 0.6230 - val_acc: 0.6467\nEpoch 7/10\n700/700 [==============================] - 79s 113ms/step - loss: 0.6276 - acc: 0.6629 - val_loss: 0.6384 - val_acc: 0.6567\nEpoch 8/10\n700/700 [==============================] - 79s 113ms/step - loss: 0.5917 - acc: 0.6829 - val_loss: 0.6116 - val_acc: 0.6733\nEpoch 9/10\n700/700 [==============================] - 77s 111ms/step - loss: 0.5735 - acc: 0.6914 - val_loss: 0.6003 - val_acc: 0.6867\nEpoch 10/10\n700/700 [==============================] - 77s 110ms/step - loss: 0.5774 - acc: 0.6943 - val_loss: 0.6227 - val_acc: 0.6700\n300/300 [==============================] - 16s 55ms/step\nTrain on 700 samples, validate on 300 samples\nEpoch 1/10\n700/700 [==============================] - 74s 106ms/step - loss: 0.9709 - acc: 0.5414 - val_loss: 0.6801 - val_acc: 0.6367\nEpoch 2/10\n700/700 [==============================] - 73s 105ms/step - loss: 0.6102 - acc: 0.6800 - val_loss: 0.6107 - val_acc: 0.7033\nEpoch 3/10\n700/700 [==============================] - 76s 108ms/step - loss: 0.5267 - acc: 0.7571 - val_loss: 0.5498 - val_acc: 0.7500\nEpoch 4/10\n700/700 [==============================] - 75s 107ms/step - loss: 0.4334 - acc: 0.8100 - val_loss: 0.5023 - val_acc: 0.7933\nEpoch 5/10\n700/700 [==============================] - 77s 110ms/step - loss: 0.3776 - acc: 0.8429 - val_loss: 0.4981 - val_acc: 0.7900\nEpoch 6/10\n700/700 [==============================] - 81s 115ms/step - loss: 0.3060 - acc: 0.8757 - val_loss: 0.4719 - val_acc: 0.8067\nEpoch 7/10\n700/700 [==============================] - 78s 111ms/step - loss: 0.2959 - acc: 0.8943 - val_loss: 0.4591 - val_acc: 0.8167\nEpoch 8/10\n700/700 [==============================] - 76s 109ms/step - loss: 0.2552 - acc: 0.9086 - val_loss: 0.4677 - val_acc: 0.8167\nEpoch 9/10\n700/700 [==============================] - 77s 111ms/step - loss: 0.2132 - acc: 0.9314 - val_loss: 0.4231 - val_acc: 0.8433\nEpoch 10/10\n700/700 [==============================] - 76s 108ms/step - loss: 0.1733 - acc: 0.9400 - val_loss: 0.4359 - val_acc: 0.8367\n300/300 [==============================] - 16s 54ms/step\nTrain on 700 samples, validate on 300 samples\nEpoch 1/10\n700/700 [==============================] - 74s 105ms/step - loss: 0.7691 - acc: 0.5914 - val_loss: 0.6229 - val_acc: 0.7200\nEpoch 2/10\n700/700 [==============================] - 76s 108ms/step - loss: 0.6015 - acc: 0.6771 - val_loss: 0.5531 - val_acc: 0.7600\nEpoch 3/10\n700/700 [==============================] - 75s 107ms/step - loss: 0.4757 - acc: 0.7886 - val_loss: 0.4586 - val_acc: 0.7833\nEpoch 4/10\n700/700 [==============================] - 78s 111ms/step - loss: 0.4029 - acc: 0.8300 - val_loss: 0.4161 - val_acc: 0.8300\nEpoch 5/10\n700/700 [==============================] - 77s 110ms/step - loss: 0.3308 - acc: 0.8543 - val_loss: 0.3763 - val_acc: 0.8600\nEpoch 6/10\n700/700 [==============================] - 78s 111ms/step - loss: 0.2860 - acc: 0.8800 - val_loss: 0.3556 - val_acc: 0.8500\nEpoch 7/10\n700/700 [==============================] - 79s 112ms/step - loss: 0.2283 - acc: 0.9200 - val_loss: 0.3050 - val_acc: 0.9000\nEpoch 8/10\n700/700 [==============================] - 80s 114ms/step - loss: 0.2059 - acc: 0.9271 - val_loss: 0.3075 - val_acc: 0.8733\nEpoch 9/10\n700/700 [==============================] - 75s 108ms/step - loss: 0.1705 - acc: 0.9286 - val_loss: 0.2939 - val_acc: 0.9033\nEpoch 10/10\n700/700 [==============================] - 77s 110ms/step - loss: 0.1621 - acc: 0.9343 - val_loss: 0.2872 - val_acc: 0.9067\n300/300 [==============================] - 18s 59ms/step\nTrain on 700 samples, validate on 300 samples\nEpoch 1/10\n700/700 [==============================] - 78s 111ms/step - loss: 1.0553 - acc: 0.4700 - val_loss: 0.6896 - val_acc: 0.5200\nEpoch 2/10\n700/700 [==============================] - 77s 110ms/step - loss: 0.6917 - acc: 0.4971 - val_loss: 0.6899 - val_acc: 0.6100\nEpoch 3/10\n700/700 [==============================] - 77s 110ms/step - loss: 0.6871 - acc: 0.5086 - val_loss: 0.6877 - val_acc: 0.5600\nEpoch 4/10\n700/700 [==============================] - 77s 110ms/step - loss: 0.6837 - acc: 0.5329 - val_loss: 0.6814 - val_acc: 0.5967\nEpoch 5/10\n700/700 [==============================] - 75s 107ms/step - loss: 0.6700 - acc: 0.6114 - val_loss: 0.6706 - val_acc: 0.6600\nEpoch 6/10\n700/700 [==============================] - 76s 108ms/step - loss: 0.6567 - acc: 0.6257 - val_loss: 0.6595 - val_acc: 0.6533\nEpoch 7/10\n700/700 [==============================] - 76s 109ms/step - loss: 0.6512 - acc: 0.6529 - val_loss: 0.6488 - val_acc: 0.6667\nEpoch 8/10\n700/700 [==============================] - 76s 108ms/step - loss: 0.6366 - acc: 0.6771 - val_loss: 0.6320 - val_acc: 0.7333\nEpoch 9/10\n700/700 [==============================] - 75s 107ms/step - loss: 0.6158 - acc: 0.6857 - val_loss: 0.6308 - val_acc: 0.7033\nEpoch 10/10\n700/700 [==============================] - 77s 110ms/step - loss: 0.5981 - acc: 0.7043 - val_loss: 0.5915 - val_acc: 0.7767\n300/300 [==============================] - 17s 57ms/step\nTrain on 700 samples, validate on 300 samples\nEpoch 1/10\n700/700 [==============================] - 78s 111ms/step - loss: 0.9004 - acc: 0.5229 - val_loss: 0.6823 - val_acc: 0.5433\nEpoch 2/10\n700/700 [==============================] - 79s 113ms/step - loss: 0.6724 - acc: 0.5900 - val_loss: 0.6588 - val_acc: 0.6233\nEpoch 3/10\n700/700 [==============================] - 78s 111ms/step - loss: 0.6614 - acc: 0.6129 - val_loss: 0.6394 - val_acc: 0.6533\nEpoch 4/10\n700/700 [==============================] - 80s 114ms/step - loss: 0.6280 - acc: 0.6214 - val_loss: 0.6341 - val_acc: 0.6567\nEpoch 5/10\n700/700 [==============================] - 78s 111ms/step - loss: 0.5732 - acc: 0.7071 - val_loss: 0.6849 - val_acc: 0.5967\nEpoch 6/10\n700/700 [==============================] - 77s 111ms/step - loss: 0.5966 - acc: 0.6829 - val_loss: 0.6168 - val_acc: 0.6833\nEpoch 7/10\n700/700 [==============================] - 78s 112ms/step - loss: 0.5801 - acc: 0.6800 - val_loss: 0.6047 - val_acc: 0.6867\nEpoch 8/10\n700/700 [==============================] - 77s 109ms/step - loss: 0.5401 - acc: 0.7371 - val_loss: 0.6203 - val_acc: 0.6567\nEpoch 9/10\n700/700 [==============================] - 76s 109ms/step - loss: 0.5289 - acc: 0.7114 - val_loss: 0.5986 - val_acc: 0.6500\nEpoch 10/10\n700/700 [==============================] - 76s 109ms/step - loss: 0.5128 - acc: 0.7529 - val_loss: 0.5765 - val_acc: 0.7200\n300/300 [==============================] - 17s 58ms/step\nTrain on 700 samples, validate on 300 samples\nEpoch 1/10\n700/700 [==============================] - 76s 109ms/step - loss: 0.7563 - acc: 0.5071 - val_loss: 0.6869 - val_acc: 0.5400\nEpoch 2/10\n700/700 [==============================] - 75s 108ms/step - loss: 0.6918 - acc: 0.5400 - val_loss: 0.6897 - val_acc: 0.5000\nEpoch 3/10\n700/700 [==============================] - 76s 108ms/step - loss: 0.6866 - acc: 0.5171 - val_loss: 0.6812 - val_acc: 0.5433\nEpoch 4/10\n700/700 [==============================] - 74s 106ms/step - loss: 0.6809 - acc: 0.5700 - val_loss: 0.6679 - val_acc: 0.6600\nEpoch 5/10\n700/700 [==============================] - 76s 108ms/step - loss: 0.6718 - acc: 0.5471 - val_loss: 0.6599 - val_acc: 0.6133\nEpoch 6/10\n700/700 [==============================] - 77s 110ms/step - loss: 0.6630 - acc: 0.5943 - val_loss: 0.6561 - val_acc: 0.5933\nEpoch 7/10\n700/700 [==============================] - 77s 110ms/step - loss: 0.6564 - acc: 0.6143 - val_loss: 0.6391 - val_acc: 0.6400\nEpoch 8/10\n700/700 [==============================] - 77s 110ms/step - loss: 0.6417 - acc: 0.6186 - val_loss: 0.6490 - val_acc: 0.6167\nEpoch 9/10\n700/700 [==============================] - 76s 108ms/step - loss: 0.6478 - acc: 0.6214 - val_loss: 0.6330 - val_acc: 0.6800\nEpoch 10/10\n700/700 [==============================] - 75s 106ms/step - loss: 0.6514 - acc: 0.6186 - val_loss: 0.6262 - val_acc: 0.6933\n300/300 [==============================] - 16s 52ms/step\n"
                }
            ], 
            "source": "Optimizer_List = ['Adam','Adadelta','Adagrad','RMSprop','Adamax','Nadam','SGD']\nScore = []\nfor j in range(0,len(Optimizer_List)):\n    model = Sequential()\n    model.add(Conv2D(16, kernel_size=(1,1),activation='relu',input_shape=input_shape, data_format= \"channels_first\"))\n    model.add(Conv2D(32, (1,1), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(64, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(2, activation='softmax'))\n    model.compile(loss='binary_crossentropy',optimizer=Optimizer_List[j] ,metrics=['accuracy'])\n    model.fit(X_train, y_train,batch_size=25, epochs=10, validation_data=(X_test, y_test))\n    Score.append(model.evaluate(X_test,y_test))\n    model.reset_states()    "
        }, 
        {
            "source": "Printing the score values.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 17, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 17, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[[0.53622841914494834, 0.78333333333333333],\n [0.62272109667460118, 0.66999999920527142],\n [0.43585414807001749, 0.83666666587193805],\n [0.28718192815780641, 0.90666666587193812],\n [0.59146838823954262, 0.77666666746139523],\n [0.57654201269149785, 0.71999999920527136],\n [0.62621420780817671, 0.69333333253860474]]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "Score"
        }, 
        {
            "source": "Printing the score values along with the respective Optimizer names.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### The Loss and Accuracy Value for the Various Optimizers\n##### Adam     : 0.53622841914494834, 0.78333333333333333\n##### Adadelta :0.62272109667460118, 0.66999999920527142\n##### Adagrad  : 0.43585414807001749, 0.83666666587193805\n##### RMSprop  : 0.28718192815780641, 0.90666666587193812\n##### Adamax   : 0.59146838823954262, 0.77666666746139523\n##### Nadam    : 0.57654201269149785, 0.71999999920527136\n##### SGD      : 0.62621420780817671, 0.69333333253860474", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#### Since RMSprop had the best traning and test accuracy (0.934 & 0.9066) respectively we choose the same for our model.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Retraining the model using the RMSprop optimizer.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 21, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Train on 700 samples, validate on 300 samples\nEpoch 1/10\n700/700 [==============================] - 77s 110ms/step - loss: 0.9383 - acc: 0.5843 - val_loss: 0.6587 - val_acc: 0.6433\nEpoch 2/10\n700/700 [==============================] - 77s 111ms/step - loss: 0.6134 - acc: 0.6614 - val_loss: 0.5709 - val_acc: 0.7233\nEpoch 3/10\n700/700 [==============================] - 77s 110ms/step - loss: 0.5417 - acc: 0.7243 - val_loss: 0.5122 - val_acc: 0.7567\nEpoch 4/10\n700/700 [==============================] - 78s 111ms/step - loss: 0.4792 - acc: 0.7957 - val_loss: 0.5160 - val_acc: 0.7133\nEpoch 5/10\n700/700 [==============================] - 77s 110ms/step - loss: 0.3957 - acc: 0.8257 - val_loss: 0.4252 - val_acc: 0.8200\nEpoch 6/10\n700/700 [==============================] - 78s 111ms/step - loss: 0.3294 - acc: 0.8714 - val_loss: 0.4188 - val_acc: 0.8300\nEpoch 7/10\n700/700 [==============================] - 79s 113ms/step - loss: 0.2777 - acc: 0.9029 - val_loss: 0.3940 - val_acc: 0.8433\nEpoch 8/10\n700/700 [==============================] - 77s 110ms/step - loss: 0.2517 - acc: 0.9114 - val_loss: 0.3754 - val_acc: 0.8567\nEpoch 9/10\n700/700 [==============================] - 88s 126ms/step - loss: 0.2082 - acc: 0.9214 - val_loss: 0.3242 - val_acc: 0.8733\nEpoch 10/10\n700/700 [==============================] - 89s 127ms/step - loss: 0.1877 - acc: 0.9329 - val_loss: 0.3359 - val_acc: 0.8733\n"
                }, 
                {
                    "execution_count": 21, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "<keras.callbacks.History at 0x7f0180116e10>"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "model_final= Sequential()\nmodel_final.add(Conv2D(16, kernel_size=(1,1),activation='relu',input_shape=input_shape, data_format= \"channels_first\"))\nmodel_final.add(Conv2D(32, (1,1), activation='relu'))\nmodel_final.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_final.add(Dropout(0.25))\nmodel_final.add(Flatten())\nmodel_final.add(Dense(64, activation='relu'))\nmodel_final.add(Dropout(0.5))\nmodel_final.add(Dense(2, activation='softmax'))\nmodel_final.compile(loss='binary_crossentropy',optimizer='RMSprop' ,metrics=['accuracy'])\nmodel_final.fit(X_train, y_train,batch_size=25, epochs=10, validation_data=(X_test, y_test))"
        }, 
        {
            "source": "Re-evaluating the model and printing the Loss and Accuracy Values.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 22, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "300/300 [==============================] - 18s 61ms/step\n"
                }
            ], 
            "source": "Score_final = model_final.evaluate(X_test,y_test)"
        }, 
        {
            "execution_count": 23, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Test_Loss : 0.335929806232\nTest_Accuracy : 0.873333334128\n"
                }
            ], 
            "source": "print('Test_Loss :', Score_final[0])\nprint('Test_Accuracy :', Score_final[1])"
        }, 
        {
            "source": "Saving the model in a .h5 file and converting the same into tar file for model deployment.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 24, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "save_path = \"Malaria_Detection_Model.h5\"\nmodel_final.save(save_path)"
        }, 
        {
            "execution_count": 25, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Malaria_Detection_Model.h5\r\n"
                }
            ], 
            "source": "!tar -zcvf Malaria_Detection_Model.tgz Malaria_Detection_Model.h5"
        }, 
        {
            "source": "Importing the WatsonMachineLearningAPIClient for model deployment.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 26, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n  \"This module will be removed in 0.20.\", DeprecationWarning)\n2019-05-25 15:16:29,680 - watson_machine_learning_client.metanames - WARNING - 'AUTHOR_EMAIL' meta prop is deprecated. It will be ignored.\n2019-05-25 15:16:30,404 - watson_machine_learning_client.wml_client_error - WARNING - Failure during creating model. (POST https://us-south.ml.cloud.ibm.com/v3/ml_assets/models)\nStatus code: 400, body: {\"trace\":\"809d60a9e33db85880210001c20abeff8558\",\"errors\":[{\"code\":\"invalid_framework_input\",\"message\":\"The framework libraries values specified: [{\\\"name\\\":\\\"keras\\\",\\\"version\\\":\\\"2.1.4\\\"}] are not supported.\"}]}\n2019-05-25 15:17:25,664 - watson_machine_learning_client.metanames - WARNING - 'AUTHOR_EMAIL' meta prop is deprecated. It will be ignored.\n2019-05-25 15:23:34,048 - watson_machine_learning_client.wml_client_error - WARNING - Deployment creation failed. Error: 400. {\"trace\":\"a26f77f0e5bf236eed23c423920fa4c6\",\"errors\":[{\"code\":\"unsupported_framework_details\",\"message\":\"Framework version 1.3.0 version of tensorflow is not supported. Supported version(s) are 1.2, 1.5, 1.11 .\"}]}\n2019-05-25 15:24:03,744 - watson_machine_learning_client.metanames - WARNING - 'AUTHOR_EMAIL' meta prop is deprecated. It will be ignored.\n"
                }
            ], 
            "source": "from watson_machine_learning_client import WatsonMachineLearningAPIClient"
        }, 
        {
            "source": "Intializing the wml credentials.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 92, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by Watson Studio for sharing."
        }, 
        {
            "source": "Creating an instance of wml using the credentials and setting the parameters for model storage.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 28, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "client = WatsonMachineLearningAPIClient(wml_credentials)"
        }, 
        {
            "execution_count": 41, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "model_props = {client.repository.ModelMetaNames.AUTHOR_NAME: \"IBM\", \n               client.repository.ModelMetaNames.AUTHOR_EMAIL: \"ibm@ibm.com\", \n               client.repository.ModelMetaNames.NAME: \"Malaria_Detection_Model\",\n               client.repository.ModelMetaNames.FRAMEWORK_NAME: \"tensorflow\",\n               client.repository.ModelMetaNames.FRAMEWORK_VERSION: \"1.5\" ,\n               client.repository.ModelMetaNames.FRAMEWORK_LIBRARIES: [{\"name\": \"keras\", \"version\": \"2.1.3\"}]\n              }"
        }, 
        {
            "source": "Storing the model and deploying the same.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 42, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "published_model = client.repository.store_model(model=\"Malaria_Detection_Model.tgz\", meta_props=model_props)"
        }, 
        {
            "execution_count": 43, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "published_model_uid = client.repository.get_model_uid(published_model)\nmodel_details = client.repository.get_details(published_model_uid)"
        }, 
        {
            "execution_count": 44, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "----  ----  ----  -----  -------  ---------  -------------\nGUID  NAME  TYPE  STATE  CREATED  FRAMEWORK  ARTIFACT TYPE\n----  ----  ----  -----  -------  ---------  -------------\n"
                }
            ], 
            "source": "client.deployments.list()"
        }, 
        {
            "execution_count": 45, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "\n\n#######################################################################################\n\nSynchronous deployment creation for uid: 'cbab4d9a-c834-400f-b1e2-e1bb4de7a737' started\n\n#######################################################################################\n\n\nINITIALIZING\nDEPLOY_IN_PROGRESS\nDEPLOY_SUCCESS\n\n\n------------------------------------------------------------------------------------------------\nSuccessfully finished deployment creation, deployment_uid='ac44e366-15d8-42a0-a0b8-ed49082695a0'\n------------------------------------------------------------------------------------------------\n\n\n"
                }
            ], 
            "source": "created_deployment = client.deployments.create(published_model_uid, name=\"Malaria Detection\")"
        }, 
        {
            "source": "#### Tetsing The Model with a random sample from the test data set", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 84, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "https://us-south.ml.cloud.ibm.com/v3/wml_instances/9b73dc07-bbe7-4ae2-a9aa-1f8e0bc7c5a0/deployments/ac44e366-15d8-42a0-a0b8-ed49082695a0/online\n"
                }
            ], 
            "source": "scoring_endpoint = created_deployment['entity']['scoring_url']\nprint(scoring_endpoint)"
        }, 
        {
            "execution_count": 85, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "The answer should be:  0\n"
                }
            ], 
            "source": "x_score_1 = X_test[168].tolist()\nprint('The answer should be: ',np.argmax(y_test[168]))\nscoring_payload = {'values': [x_score_1]}"
        }, 
        {
            "execution_count": 86, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "And the answer is!...  0\n"
                }
            ], 
            "source": "predictions = client.deployments.score(scoring_endpoint, scoring_payload)\nprint('And the answer is!... ',predictions['values'][0][1])"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.5", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}